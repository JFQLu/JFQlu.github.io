<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <title>GraphX Reachable Vertices</title>
    <meta name="description" content="GraphX Reachable Vertices" />

    <link rel="stylesheet" href="css/style.css" />

    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@400;600;700;900&display=swap"
      rel="stylesheet"
    />
  </head>
  <body>
    <header class="header">
      <div class="header__content">
        <div class="header__logo-container">
          <div class="header__logo-img-cont">
            <img
              src="./assets/png/james_lu.png"
              alt="James Lu Logo Image"
              class="header__logo-img"
            />
          </div>
          <span class="header__logo-sub">James Lu</span>
        </div>
        <div class="header__main">
          <ul class="header__links">
            <li class="header__link-wrapper">
              <a href="./index.html" class="header__link"> Home </a>
            </li>
            <li class="header__link-wrapper">
              <a href="./index.html#about" class="header__link">About </a>
            </li>
            <li class="header__link-wrapper">
              <a href="./index.html#projects" class="header__link">
                Projects
              </a>
            </li>
            <li class="header__link-wrapper">
              <a href="./index.html#contact" class="header__link"> Contact </a>
            </li>
          </ul>
          <div class="header__main-ham-menu-cont">
            <img
              src="./assets/svg/ham-menu.svg"
              alt="hamburger menu"
              class="header__main-ham-menu"
            />
            <img
              src="./assets/svg/ham-menu-close.svg"
              alt="hamburger menu close"
              class="header__main-ham-menu-close d-none"
            />
          </div>
        </div>
      </div>
      <div class="header__sm-menu">
        <div class="header__sm-menu-content">
          <ul class="header__sm-menu-links">
            <li class="header__sm-menu-link">
              <a href="./index.html"> Home </a>
            </li>

            <li class="header__sm-menu-link">
              <a href="./index.html#about"> About </a>
            </li>

            <li class="header__sm-menu-link">
              <a href="./index.html#projects"> Projects </a>
            </li>

            <li class="header__sm-menu-link">
              <a href="./index.html#contact"> Contact </a>
            </li>
          </ul>
        </div>
      </div>
    </header>
    <!--- Hero Section
    <section class="project-cs-hero">
      <div class="project-cs-hero__content">
        <h1 class="heading-primary">Reachable Vertices in Directed Graph using GraphX</h1>
        <div class="project-cs-hero__info">
          <p class="text-primary">
            Predictive analysis and
          </p>
        </div>
        <div class="project-cs-hero__cta">
          <a href="#" class="btn btn--bg" target="_blank">Live Link</a>
        </div>
      </div>
    </section>
    --->
    <section class="project-details">
      <div class="main-container">
        <div class="project-details__content">
          <h3 class="project-details__content-project_heading">Reachable Vertices in Directed Graph using GraphX</h3>
          <!--- Hero Image
          <div class="project-details__showcase-img-cont">
            <img
              src="./assets/jpeg/network_anomaly_detection_hero_img.jpg"
              alt="Project Image Hero"
              class="project-details__showcase-img"
            />
          </div>
          ---> 
          <div class="project-details__content-main">
            <div class="project-details__desc">
              <h3 class="project-details__content-title_1">Project Overview</h3>
              <p class="project-details__desc-para">
                This project was conducted as coursework in Big Data Management (COMP9313) at UNSW. The problem states:
              </p>
              <h3 class="project-details__content-title_1">Background</h3>
              <p class="project-details__desc-para">
                "Given a directed graph, for each vertex v, compute the number of vertices that are reachable from v in the graph (including v itself if there is a path starting from v and ending at v). 
                For example, for node 0, the number of vertices that are reachable from 0 is 6, since there exists a path from node 0 to each node in the graph."
              </p>
              <p class="project-details__desc-para">
                This project requires the use of the Apache Spark big data processing framework, specifically, GraphX which provides an API for graph (vertices and edges) processing.
              </p>
              <p class="project-details__desc-para">
                GraphX extends the Spark RDD (Resilient Distributed Dataset) API to support graph processing by providing a set of graph-specific RDDs, which are distributed collections of data that can be processed in parallel. 
                These include VertexRDD, EdgeRDD, and Graph.
              </p>
              <p class="project-details__desc-para">
                The Pregel operator will be important in solving this problem. The Pregel operator performs the computation in a series of supersteps, with each superstep consisting of the following steps:
              </p>
              <p class="project-details__desc-para">
                We observe that there is 10% more neural sentiment tweets compared to the negative and positive classes which may be a potential issue biasing models toward the more prevalent class. 
                Since the difference is only 10% we will ignore this however a potential remedy for this would be to oversample the less prevelent classes or to undersample the more prevalent class.
              </p>
              <p class="project-details__desc-para">
                Now, observing tweet length distributions across sentiments,
              </p>
              <div class="div-list">
                <ol>
                  <li>
                    <p class="project-details__desc-list_ele">1. Each vertex receives the messages sent to it in the previous superstep and executes the vertex program, possibly updating its data and sending new messages to its neighbors.</p>
                  </li>
                  <li>
                    <p class="project-details__desc-list_ele">2. The messages are collected and stored in a message buffer.</p>
                  </li>
                  <li>
                    <p class="project-details__desc-list_ele">3. The vertex program of each vertex is executed again, this time using the updated message buffer.</p>
                  </li>
                </ol>
              </div>
              <p class="project-details__desc-para">
                This process is repeated until the algorithm converges or a maximum number of supersteps is reached.
              </p>
              <p class="project-details__desc-para">
                To solve our problem above we start by importing the required libraries.
              </p>
              <div class="div-code">
                <p>import org.apache.spark.SparkContext</p>
                <p>import org.apache.spark.SparkContext._</p>
                <p>import org.apache.spark.SparkConf</p>
                <p>import org.apache.spark.graphx._</p>
              </div>
              <p class="project-details__desc-para">
                Next, we must define a vertex program. This is a user-defined function that is executed on each vertex in the graph. 
                It takes as input the vertex ID, the current vertex data, and a message received by the vertex in the previous superstep, and it returns an updated vertex data. 
                Here we have the vertex program take the message (newData) and merge it with the vertex data (origData) removing duplicates, i.e. we take the union of newData and origData.
              </p>
              <div class="div-code">
                <p>// Vertex Program: merges vertex data (List[VertexId]) with message (List[VertexId]) removing duplicates </p>
                <p>def vertexProgram(id: VertexId, origData: List[VertexId], newData: List[VertexId]) : List[VertexId] = ( origData ::: newData ).distinct</p>
              </div>
              <p class="project-details__desc-para">
                We also define a mergeMsg function, this has no access to the context of any Vertex -- 
                it just takes individual messages and creates a single message which is then sent to the vertex program as newData. 
                Here we simply take the union of all messages.
              </p>
              <div class="div-code">
                <p>def mergeMsg(list1: List[VertexId], list2: List[VertexId]) : List[VertexId] = (list1 ::: list2).distinct</p>
              </div>
              <p class="project-details__desc-para">
                Finally, we define a sendMsg function, it takes as input the source and destination vertices of the edge, and it returns a message to be sent from the source vertex to the destination vertex. 
                Here we first check if the vertex is reachable from itself. We also check if there are any messages that need to be added to srcAttr.
              </p>
              <div class="div-code">
                <p>def sendMsg(triplet: EdgeTriplet[List[VertexId],Double]) : Iterator[(VertexId, List[VertexId])] = {</p>
                <p>&emsp;// Append destination vertexId with destination vertexAttribute (List[VertexId]) and save to new val</p>
                <p>&emsp;val newList = (triplet.dstId :: triplet.dstAttr).distinct</p>
                <p>&nbsp;</p>
                <p>&emsp;// Note that we are sending messages to the source vertex from the destination vertex (ie. we "flip" the direction of edges in the graph)</p>
                <p>&emsp;// If source vertex is also reachable from destination vertex then the source node can reach itself</p>
                <p>&emsp;if (triplet.srcAttr == triplet.dstAttr) {</p>
                <p>&emsp;&emsp;Iterator((triplet.srcId, newList)</p>
                <p>&emsp;// If the srcAttr list is the same length as the newList formed through recursion, then there is nothing new to add to the srcAttr list</p>
                <p>&emsp;} else if (triplet.srcAttr.intersect(newList).length != newList.length) {</p>
                <p>&emsp;&emsp;Iterator((triplet.srcId, newList))</p>
                <p>&emsp;} else {</p>
                <p>&emsp;&emsp;Iterator.empty</p>
                <p>&emsp;}</p>
                <p>}</p>
              </div>
              
              
              
              <h3 class="project-details__content-title_2">Removing HTML tags</h3>
              <p class="project-details__desc-para">
                HTML tags should be removed as they do not provide information on the sentiment of a tweet.
              </p>
              <div class="div-code">
                <p>from bs4 import BeautifulSoup</p>
                <p>def remove_html_tags(text):</p>
                <p>&emsp;return BeautifulSoup(text).get_text()</p>
                <p>&nbsp;</p>
                <p>df_train['text']= df_train['text'].apply(lambda x : remove_html_tags(x))</p>
                <p>df_test['text'] = df_test['text'].apply(lambda x: remove_html_tags(x))</p>
              </div>
              <h3 class="project-details__content-title_2">Spelling correction</h3>
              <p class="project-details__desc-para">
                There may be spelling mistakes in the tweets, these should be corrected to reduce dimensionality/complexity and improve accuracy.
              </p>
              <div class="div-code">
                <p>from spellchecker import SpellChecker</p>
                <p>&nbsp;</p>
                <p>spell = SpellChecker()</p>
                <p>def correct_spellings(text):</p>
                <p>&emsp;corrected_text = []</p>
                <p>&emsp;misspelled_words = spell.unknown(text.split())</p>
                <p>&emsp;for word in text.split():</p>
                <p>&emsp;&emsp;if word in misspelled_words:</p>
                <p>&emsp;&emsp;&emsp;corrected_text.append(spell.correction(word))</p>
                <p>&emsp;&emsp;else:</p>
                <p>&emsp;&emsp;&emsp;corrected_text.append(word)</p>
                <p>&emsp;return " ".join(corrected_text)</p>
                <p>&nbsp;</p>
                <p>df_train['text']=df_train['text'].apply(lambda x : correct_spellings(x))</p>
                <p>df_test['text'] = df_test['text'].apply(lambda x: correct_spellings(x))</p>
              </div>
              <h3 class="project-details__content-title_2">Removing Stop Words</h3>
              <p class="project-details__desc-para">
                Finally, we remove stop words such as "in", "on", "with", "by" and "for" since these do not provide much information on the sentiment of tweets and will only add unnecessary complexity to our models.
              </p>
              <p class="project-details__desc-para">
                First, we create a string version containing a list of words for further EDA,
              </p>
              <div class="div-code">
                <p>df_train['temp_list'] = df_train['text'].apply(lambda x:str(x).split())</p>
                <p>&nbsp;</p>
                <p># Str version for EDA</p>
                <p>def correct_spellings(text):</p>
                <p>def remove_stopword(x):</p>
                <p>&emsp;return [y for y in x if y not in stopwords.words('english')]</p>
                <p>&emsp;df_train['temp_list'] = df_train['temp_list'].apply(lambda x:remove_stopword(x))</p>
              </div>
              <p class="project-details__desc-para">
                we also create a text version which will be used for TF-IDF vectorisation later.
              </p>
              <div class="div-code">
                <p># Text version for tfidf vectorisation</p>
                <p>import nltk</p>
                <p>nltk.download('stopwords')</p>
                <p>def remove_stopword(x):</p>
                <p>&emsp;new = ""</p>
                <p>&emsp;for y in x.split():</p>
                <p>&emsp;&emsp;if y not in stopwords.words('english'):</p>
                <p>&emsp;&emsp;&emsp;new = f'{new}{y} '</p>
                <p>&emsp;return new.rstrip()</p>
                <p>df_train['text'] = df_train['text'].apply(lambda x:remove_stopword(x))</p>
                <p>df_test['text'] = df_test['text'].apply(lambda x:remove_stopword(x))</p>
              </div>
              <h3 class="project-details__content-title_1">Post-Preprocessing Data Exploration</h3>
              <p class="project-details__desc-para">
                Now that preprocessing has been done we have a look at the most common words in each sentiment class. First, lets separate the sentiments.
              </p>
              <div class="div-code">
                <p>Pt_sent = df_train[df_train['sentiment']==1]</p>
                <p>Ng_sent = df_train[df_train['sentiment']==-1]</p>
                <p>Nt_sent = df_train[df_train['sentiment']==0]</p>
              </div>
              <p class="project-details__desc-para">
                Now we look at the most common words for each class.
              </p>
              <div class="div-code">
                <p>from collections import Counter</p>
                <p># Most common words for each sentiment</p>
                <p>for sentiment in [(Pt_sent, 'Greens'), (Nt_sent, 'Blues'), (Ng_sent, 'Reds')]:</p>
                <p>&emsp;top = Counter([item for sublist in sentiment[0]['temp_list'] for item in sublist])</p>
                <p>&emsp;temp_sent = pd.DataFrame(top.most_common(20))</p>
                <p>&emsp;temp_sent.columns = ['Common_words','count']</p>
                <p>&emsp;display(temp_sent.style.background_gradient(cmap=sentiment[1]))</p>
              </div>
              <img
                src="./assets/jpeg/tsa_most_common_words.jpg"
                alt="Project Image Hero"
                class="project-details__showcase-img"
              />
              <h3 class="project-details__content-title_1">Modeling</h3>
              <h3 class="project-details__content-title_2">TF-IDF</h3>
              <p class="project-details__desc-para">
                TF-IDF (Term Frequency-Inverse Document Frequency) is a common technique used in natural language processing (NLP) to represent the importance of words in a document. 
                It is typically used to transform text data into numerical vectors that can be used as input to machine learning models.
              </p>
              <p class="project-details__desc-para">
                We will be applying this vectorizer to our pre-processed data to extract features for our machine learning models.
              </p>
              <div class="div-code">
                <p>from sklearn.feature_extraction.text import TfidfVectorizer</p>
                <p>vectorizer = TfidfVectorizer(max_features=1024)</p>
                <p>X_train = vectorizer.fit_transform(df_train['text'])</p>
                <p>X_train = np.array(X_train.toarray())</p>
                <p>y_train = np.array(df_train['sentiment'])</p>
                <p>&nbsp;</p>
                <p>X_test = vectorizer.transform(df_test['text'])</p>
                <p>X_test = np.array(X_test.toarray())</p>
                <p>y_test = np.array(df_test['sentiment'])</p>
              </div>
              <h3 class="project-details__content-title_1">Logistic Regression</h3>
              <p class="project-details__desc-para">
                The first model we will be training is the logistic regression. 
                Logistic regression is a generalised linear model and assumes that the data follows a Bernoulli distribution. 
                Logistic regression solves for the parameters by maximising the likelihood function and applying gradient descent. 
                The structure of the logistic regression model is simple and interpretable, and the influence of different features on the final results can be seen from the weights of the features.
              </p>
              <p class="project-details__desc-para">
                We use the sklearn implementation of logistic regression and grid-search for hyperparameter tuning.
              </p>
              <div class="div-code">
                <p>from sklearn.model_selection import GridSearchCV</p>
                <p>from sklearn.linear_model import LogisticRegression</p>
                <p>grid={"C":np.linspace(0,10,11), "penalty":["l1","l2"]}# l1 lasso l2 ridge</p>
                <p>logreg=LogisticRegression()</p>
                <p>logreg_cv=GridSearchCV(logreg,grid,cv=10)</p>
                <p>logreg_cv.fit(X_train,y_train)</p>
                <p>&nbsp;</p>
                <p>print("tuned hpyerparameters :(best parameters) ",logreg_cv.best_params_)</p>
                <p>print("accuracy :",logreg_cv.best_score_)</p>
              </div>
              <p class="project-details__desc-para">
                We can then use this model to predict on the training set.
              </p>
              <div class="div-code">
                <p>clf = LogisticRegression(penalty=logreg_cv.best_params_['penalty'], C=logreg_cv.best_params_['C'])</p>
                <p>clf.fit(X_train, y_train)</p>
                <p>y_pred = clf.predict(X_test)</p>
                <p>print('test acc: %.2f%%, test f1 score: %.4f' % (100 * accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')))</p>
              </div>
              <div class="div-list">
                <ul>
                  <li>
                    <p class="project-details__desc-list_ele">&bull; Test accuracy = 68.48%</p>
                  </li>
                  <li>
                    <p class="project-details__desc-list_ele">&bull; Test f1 score = 0.6849</p>
                  </li>
                </ul>
              </div>
              <p class="project-details__desc-para">
                Multilayer Perceptron - details to be added
              </p>
            </div> 
            <div class="project-details__tools-used">
              <h3 class="project-details__content-title_1">Tools Used</h3>
              <div class="skills">
                <div class="skills__skill">Python</div>
                <div class="skills__skill">Sklearn</div>
                <div class="skills__skill">Natural Language Processing</div>
                <div class="skills__skill">Machine Learning</div>
                <div class="skills__skill">Deep Learning</div>
                <div class="skills__skill">Jupyter</div>
                <div class="skills__skill">Matplotlib</div>
                <div class="skills__skill">Seaborn</div>
              </div>
            </div>
            <!---
            <div class="project-details__links">
              <h3 class="project-details__content-title_1">See Live</h3>
              <a
                href="#"
                class="btn btn--med btn--theme project-details__links-btn"
                target="_blank"
                >Live Link</a
              >
              <a
                href="#"
                class="btn btn--med btn--theme-inv project-details__links-btn"
                target="_blank"
                >Code Link</a
              >
            </div>
            --->
          </div>
        </div>
      </div>
    </section>
    <footer class="main-footer">
      <div class="main-container">
        <div class="main-footer__upper">
          <div class="main-footer__row main-footer__row-1">
            <h2 class="heading heading-sm main-footer__heading-sm">
              <span>Social</span>
            </h2>
            <div class="main-footer__social-cont">
              <a target="_blank" rel="noreferrer" href="#">
                <img
                  class="main-footer__icon"
                  src="./assets/png/linkedin-ico.png"
                  alt="icon"
                />
              </a>
              <a target="_blank" rel="noreferrer" href="#">
                <img
                  class="main-footer__icon"
                  src="./assets/png/github-ico.png"
                  alt="icon"
                />
              </a>
            </div>
          </div>
          <div class="main-footer__row main-footer__row-2">
            <h4 class="heading heading-sm text-lt">James Lu</h4>
            <p class="main-footer__short-desc">
              Getting the most out of data...
            </p>
          </div>
        </div>
      </div>
    </footer>
    <script src="./index.js"></script>
  </body>
</html>
